{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Ollama for local inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in ./.venv/lib/python3.13/site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in ./.venv/lib/python3.13/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in ./.venv/lib/python3.13/site-packages (from ollama) (2.10.6)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a 2-line poem about a dog:\n",
      "\n",
      "With wagging tail and loving eyes,\n",
      "Faithful companion, always by our side.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# MODEL = \"deepseek-r1:1.5b\"\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def get_llm_response(prompt: str) -> str:\n",
    "    response: ChatResponse = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.message.content\n",
    "\n",
    "prompt = 'Hello! write me a 2 liner poem about a dog?'\n",
    "print(get_llm_response(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COT w/ Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def get_cot_response(question: str) -> Tuple[str, str]:\n",
    "    prompt = f\"\"\"\n",
    "question: `{question}`\n",
    "-------------------\n",
    "Answer the given question, be critical in your thinking process.\n",
    "Provide a detailed reasoning process, and a verification process.\n",
    "Respond in the following format:\n",
    "\n",
    "Reasoning:\n",
    "detailed reasonging process\n",
    "\n",
    "Verification:\n",
    "Cross checking and reflection process\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    response = get_llm_response(prompt)\n",
    "    final_answer = response.split(\"Answer:\")[1].strip()\n",
    "    return final_answer, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The farmer will collect a total of 154 (34 eggs + 120 liters) eggs and liters of milk in one day.\n"
     ]
    }
   ],
   "source": [
    "question = \"A farmer has 17 chickens and 12 cows. If each chicken lays 2 eggs per day and each cow produces 10 liters of milk per day, how many eggs and liters of milk will the farmer collect in total in one day?\"\n",
    "answer, llm_resp = get_cot_response(question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "1. Critique\n",
    "2. Improve\n",
    "3. Rate / Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critique(question: str, answer: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "question: `{question}`\n",
    "answer: `{answer}`\n",
    "-------------------\n",
    "Please critique the answer carefully.\n",
    "Assess for correctness, and point out any errors.\n",
    "Be verbose and go step by step.\n",
    "Do not give any answer, just suggest a few obvious improvements.\n",
    "Give bullets of Assessment and suggested improvements, followed by the conclusion.\n",
    "\"\"\"\n",
    "    return get_llm_response(prompt)\n",
    "\n",
    "\n",
    "# print(critique(\"What is the capital of India?\", \"Bangalore is the Capital of India.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_answer(question: str, answer: str, critique: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "question: `{question}`\n",
    "answer: `{answer}`\n",
    "critique: `{critique}`\n",
    "-------------------\n",
    "\n",
    "Improve the answer based on the critique. Respond in the following format:\n",
    "\n",
    "Reasoning:\n",
    "detailed reasonging process\n",
    "\n",
    "Verification:\n",
    "Cross checking and reflection process\n",
    "\n",
    "Corrected Answer:\n",
    "Improved answer\n",
    "\"\"\"\n",
    "    return get_llm_response(prompt)\n",
    "\n",
    "# print(improve_answer(\"What is the capital of India?\", \"India's capital is Bangalore.\", \"The answer is incorrect because it is not the capital of India.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rate_answer(question: str, answer: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "question: `{question}`\n",
    "answer: `{answer}`\n",
    "-------------------\n",
    "\n",
    "You are an expert in evaluating student answers.\n",
    "Go throught the answer carefully and give a score between 0 and 100.\n",
    "Take into account the explanation steps as well for evaluation, and give partial marks for correct steps.\n",
    "Respond in the following format:\n",
    "\n",
    "Thought: <verification steps and critique>\n",
    "\n",
    "Score: <Score between 0 and 100>\n",
    "\"\"\"\n",
    "    response = get_llm_response(prompt)\n",
    "    try:\n",
    "        match = re.search(r\"Score:\\s*(\\d+)\", response)\n",
    "        if match:\n",
    "            score = int(match.group(1))\n",
    "            if score < 0 or score > 100:\n",
    "                raise ValueError(\"Score out of range\")\n",
    "            return float(score)/100\n",
    "        else:\n",
    "            raise ValueError(\"Score not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# print(rate_answer(\"What is the capital of India?\", \"India's capital is Delhi.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHILDREN = 3\n",
    "MAX_ITERATIONS = 2\n",
    "EXPLORATION_CONSTANT = 1.414\n",
    "\n",
    "SEED_ANSWERS = [\n",
    "    \"I do not know\",\n",
    "    \"I can not understand\",\n",
    "    \"I am quite confused\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, question: str, answer: str, id: str, parent: \"TreeNode\" = None):\n",
    "        self.id = id\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.parent = parent\n",
    "        self.children: list[\"TreeNode\"] = []\n",
    "        self.visits = 0\n",
    "        self.value = 0.0\n",
    "        print(f\">> INIT node {self.id}\")\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "\n",
    "    def is_full(self):\n",
    "        return len(self.children) >= MAX_CHILDREN\n",
    "\n",
    "    def add_child(self, child_node: \"TreeNode\"):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def most_visited_child(self):\n",
    "        return max(self.children, key=lambda x: x.visits)\n",
    "\n",
    "    def best_child(self):\n",
    "        weights = []\n",
    "        for c in self.children:\n",
    "            if c.visits == 0:\n",
    "                weight = float('inf')\n",
    "            else:\n",
    "                exploitation = c.value / c.visits\n",
    "                exploration = math.sqrt(math.log(c.visits+1) / self.visits)\n",
    "                weight = exploitation + (EXPLORATION_CONSTANT * exploration)\n",
    "            weights.append(weight)\n",
    "        max_weight = max(weights)\n",
    "        best_child_index = weights.index(max_weight)\n",
    "        best_child = self.children[best_child_index]\n",
    "        print(\">>>> Best child of\", self.id, \"is\", best_child.id, \"with weight\", max(weights))\n",
    "        return best_child\n",
    "\n",
    "    def expand(self):\n",
    "        print(f\">> Expanding node {self.id}\")\n",
    "        for i in range(MAX_CHILDREN):\n",
    "            child_node = TreeNode(self.question, self.answer, self.id+str(i), self)\n",
    "            print(f\">>> Child {child_node.id}\")\n",
    "            critique = get_critique(self.question, child_node.answer)\n",
    "            # print(f\">>> Critique: {critique}\")\n",
    "            improved_answer = improve_answer(self.question, child_node.answer, critique)\n",
    "            child_node.answer = improved_answer\n",
    "            print(f\">>> Improved answer: {improved_answer}\")\n",
    "            self.add_child(child_node)\n",
    "\n",
    "    def print_node(self):\n",
    "        print(f\">> Node {self.id}\")\n",
    "        print(f\">> Answer: {self.answer}\")\n",
    "        print(f\">> Visits: {self.visits}\")\n",
    "        print(f\">> Value: {self.value}\")\n",
    "        print(f\">> Children: {len(self.children)}\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "class TreeSearch:\n",
    "    def __init__(self, question: str):\n",
    "        self.question = question\n",
    "        self.root = TreeNode(question, random.choice(SEED_ANSWERS), \"0\")\n",
    "\n",
    "    def print_tree(self, node: TreeNode):\n",
    "        \"\"\"\n",
    "        Print the tree in a readable format\n",
    "        \"\"\"\n",
    "        node.print_node()\n",
    "        for child in node.children:\n",
    "            self.print_tree(child)\n",
    "\n",
    "    def select_candidate(self):\n",
    "        node = self.root\n",
    "        while not node.is_leaf():\n",
    "            node = node.best_child()\n",
    "        return node\n",
    "\n",
    "    def backprop(self, node: TreeNode, reward: float):\n",
    "        \"\"\"\n",
    "        Backpropagate the reward to the parent nodes -> update the visits and value\n",
    "        \"\"\"\n",
    "        while node is not None:\n",
    "            node.visits += 1\n",
    "            node.value += reward\n",
    "            node = node.parent\n",
    "\n",
    "    def search(self):\n",
    "        for i in range(MAX_ITERATIONS):\n",
    "            print(f\"> Iteration {i+1} of {MAX_ITERATIONS}\")\n",
    "            candidate = self.select_candidate()\n",
    "            if candidate.is_leaf():\n",
    "                candidate.expand()\n",
    "                # on expansion, we added all new children to the leaf node\n",
    "                candidate = random.choice(candidate.children)\n",
    "\n",
    "            print(f\"> Selected candidate: {candidate.id}\")\n",
    "            print(f\"> Candidate answer: {candidate.answer}\")\n",
    "            rating = rate_answer(candidate.question, candidate.answer)\n",
    "            print(f\"> Rating: {rating}\")\n",
    "            self.backprop(candidate, rating)\n",
    "        print(\"-------DONE-------\")\n",
    "\n",
    "        return self.root.most_visited_child()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = TreeSearch(\"How many R's are there in the word 'strawberry'?\").search()\n",
    "\n",
    "print(result.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
